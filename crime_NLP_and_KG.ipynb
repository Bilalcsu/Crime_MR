{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cadfdf23-6aae-4d7c-b76d-1d8be24cd91f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['Report Number', 'Report DateTime', 'Offense ID', 'Offense Date', 'NIBRS Group AB', 'NIBRS Crime Against Category', 'Offense Sub Category', 'Shooting Type Group', 'Block Address', 'Latitude', 'Longitude', 'Beat', 'Precinct', 'Sector', 'Neighborhood', 'Reporting Area', 'Offense Category', 'NIBRS Offense Code Description', 'NIBRS_offense_code', 'Report DateTime_std', 'Offense Date_std']\n"
     ]
    }
   ],
   "source": [
    "# 02_Crime_NLP_and_KG.ipynb\n",
    "# Phase II – Step 1: NLP Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# 1️⃣ Load the cleaned dataset from Phase I\n",
    "df = pd.read_csv(\"data/crime_data_cleaned.csv\")\n",
    "\n",
    "# 2️⃣ Strip extra spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 3️⃣ Confirm columns\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f0360f-78f5-46bb-9638-7d42bba442b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy NLP model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"spaCy NLP model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ec111c-281f-4c7a-98e7-845c7dcc8b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing function defined.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove stopwords/punctuation, lemmatize words.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "print(\"Preprocessing function defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75a6c07-49e5-49ff-8b16-7554639e8932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offense description cleaned using nlp.pipe.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Apply preprocessing to offense description using nlp.pipe (much faster)\n",
    "texts = df['NIBRS Offense Code Description'].fillna(\"\").tolist()\n",
    "cleaned_texts = []\n",
    "\n",
    "for doc in nlp.pipe(texts, batch_size=1000, n_process=2):  # adjust n_process to CPU cores\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    cleaned_texts.append(\" \".join(tokens))\n",
    "\n",
    "df['Offense_Description_Clean'] = cleaned_texts\n",
    "print(\"Offense description cleaned using nlp.pipe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ad7244-9021-453a-a9ae-0e83b6d1dded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved as 'data/crime_data_nlppreprocessed.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Save preprocessed dataset for later use\n",
    "df.to_csv(\"data/crime_data_nlppreprocessed.csv\", index=False)\n",
    "print(\"Preprocessed dataset saved as 'data/crime_data_nlppreprocessed.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8b506-c71e-4998-ad77-36df4026bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_Crime_NLP_and_KG.ipynb\n",
    "# Phase II – Step 1: NLP Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# 1️⃣ Load cleaned dataset from Phase I\n",
    "df = pd.read_csv(\"data/crime_data_cleaned.csv\")\n",
    "\n",
    "# 2️⃣ Strip extra spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 3️⃣ Confirm columns\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "\n",
    "# 4️⃣ Load spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 5️⃣ Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# 6️⃣ Apply preprocessing to correct text columns\n",
    "df['Offense_Description_Clean'] = df['NIBRS Offense Code Description'].apply(preprocess_text)\n",
    "df['Category_Clean'] = df['Offense Category'].apply(preprocess_text)\n",
    "\n",
    "# 7️⃣ Quick check\n",
    "df[['NIBRS Offense Code Description', 'Offense_Description_Clean']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d19c9-cf2f-4463-a606-05f6ef355d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
